Objectif : Montrer via un outil et un cas d’usage (fournir dataset) comment on peut expliquer à des parties prenantes et justifier les résultats obtenus
Forme : Outil ? (shap, shapash, AI 360..)

Introduction différentes méthodes pour explicabilité (permutations, shap, ..)
- Concept des Shapley values, et complexité algorithmique exponentielle
- Nécessité d'approximations
  - Librairie shap en python : en fonction des algos, différentes méthodes
  - Exemple sur datasets
- Présentation de Shapash ac exemple
- Présentation d'AI 360 ac exemple
- Les Shap values en dev, c'est bien, mais quid de l'explicabilité une fois le modèle en production : comment amener l'explicabilité à l'utilisateur ?   (transition avec L10)
